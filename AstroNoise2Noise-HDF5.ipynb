{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f264797d",
   "metadata": {},
   "source": [
    "# Training with HDF5 Data\n",
    "\n",
    "In order to allow larger sets of data to be processed with limited system memory we take advantage of HDF5 and the [h5py package](https://www.h5py.org/).\n",
    "\n",
    "This allows us to incrementally save our pre-processed and randomised data to disk, and then incrementally load the data using iterable tensors for training.\n",
    "\n",
    "In contrast to the main example notebook `AstroNoise2Noise.ipynb`, in this example we train with two sets of subs from different targets resulting in substantially more data.\n",
    "\n",
    "*Enhancements have been provided by Maria Pavlou as code changes to the base CDBDeep repo.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "509cfb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow reloading of CSBDeep modules following any code changes\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# A couple required imports\n",
    "import numpy as np\n",
    "from tifffile import imread\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7361afc9",
   "metadata": {},
   "source": [
    "# Pre-processing Training Data and Save\n",
    "\n",
    "We have two sets of sub frames in the `data/astro` sub-folders `NGC6888` and `NGC7000`, acquired with the same optical train and equipment.\n",
    "\n",
    "All images have been aligned and calibrated and saved in the tiff format.\n",
    "\n",
    "The example data can be downloaded [here](https://1drv.ms/u/s!AvWEkn9Anb_Nq9Aw52Xs3LuYEcq_rg?e=EexXxL)\n",
    "\n",
    "Place the train images in sub-folders under the `data/astro` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a5bcc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Data Parameters:\n",
    "# Root Data path\n",
    "basepath=Path('data/astro')\n",
    "# Train Data path/s\n",
    "source_dirs=['NGC6888','NGC7000']\n",
    "# Image file pattern. Note: only formats supported by imread currently\n",
    "pattern='*.tiff'\n",
    "# Image patch size\n",
    "patchsize=64\n",
    "# Training data output savefile path & name\n",
    "training_data_name='NGC7000_NGC6888_p64_nPERC'\n",
    "training_data_filename=training_data_name + '.hdf5'\n",
    "save_file=basepath/training_data_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f30eeadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an estimate of the number of non-overlapping patches for the images we have, sampling from the first we find.\n",
    "first_image_file = list((basepath/source_dirs[0]).glob(pattern))[0]\n",
    "sampleimage = imread(first_image_file)\n",
    "n_patches_per_image=np.int(sampleimage.shape[0]/patchsize)*np.int(sampleimage.shape[1]/patchsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8485ba39",
   "metadata": {},
   "source": [
    "# Save pre-processed data to HDF5\n",
    "\n",
    "No we use the `create_patches_hdf5` helper to create the sampled patches from the sub frame images, and store these directly to disk as an HDF5 file.\n",
    "\n",
    "**Note:**\n",
    "\n",
    "* Saving to disk will take longer, and significantly longer depending on your system configuration\n",
    "* Randomised indexing cannot be used when writing to HDF5 Datasets. A secondary read/write process is used to achieve a compromised shuffle on the raw data. This can take some time, but leads to improved performance during training. A good tradeoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "268658ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================\n",
      "  380 raw images x    1 transformations   =   380 images\n",
      "  380 images     x  884 patches per image = 335920 patches in total\n",
      "==================================================================\n",
      "Input data:\n",
      "data\\astro:, sources='['NGC6888', 'NGC7000']', axes='YXC', pattern='*.tiff'\n",
      "==================================================================\n",
      "Transformations:\n",
      "1 x Identity\n",
      "==================================================================\n",
      "Patch size:\n",
      "64 x 64 x 3\n",
      "==================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pydeep\\astro-csbdeep\\csbdeep\\data\\generate_hdf5.py:111: RuntimeWarning: overflow encountered in long_scalars\n",
      "  n_required_memory_bytes = 2 * n_patches*np.prod(patch_size) * 4\n",
      "100%|██████████| 380/380 [09:57<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as hdf5 data to data\\astro\\NGC7000_NGC6888_p64_nPERC.hdf5.\n"
     ]
    }
   ],
   "source": [
    "from csbdeep.data import RawData, create_patches, create_patches_hdf5, norm_percentiles, norm_reinhard\n",
    "from csbdeep.data import NoPreProcessor, ReinhardPreProcessor\n",
    "\n",
    "# Load image pairs for Noise2Noise processing, each image paired against every other at most once.\n",
    "raw_data = RawData.from_folder_n2n(basepath, source_dirs=source_dirs, axes='YXC', pattern=pattern, preprocessor=NoPreProcessor(), imageloader=None)\n",
    "\n",
    "# Create patch data from image pairs with parameters,\n",
    "# normalization set as norm_percentiles() by default, optionally set to None, norm_reinhard() or other custom\n",
    "create_patches_hdf5(\n",
    "    raw_data, \n",
    "    patch_size=(patchsize,patchsize,3),\n",
    "    normalization=norm_percentiles(),\n",
    "    n_patches_per_image=n_patches_per_image,\n",
    "    save_file=save_file,\n",
    "    patch_filter=None,\n",
    "    overlap=False,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47711ff",
   "metadata": {},
   "source": [
    "# Load Training Data\n",
    "Here we load the training data from a save file created in earlier steps.\n",
    "As data is loaded we can also split the data into training `X,Y` and validation `X_val,Y_val` sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2cc39ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape = (302328, 64, 64, 3)\n",
      "Val Data Shape = (33592, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "from csbdeep.data.generate_hdf5 import HDF5Data\n",
    "\n",
    "# Train/Validation split %\n",
    "validation_split=0.1\n",
    "# Select 1st channel initially\n",
    "channel_slice = slice(0,1)\n",
    "# Since we have shuffles the raw data we disable this for performance\n",
    "hdf5_shuffled_read = False\n",
    "\n",
    "# Load saved training and validation from HDF5 data with iterable wrapper object and channel selection\n",
    "train_data, val_data = HDF5Data.from_hdf5(save_file, validation_split=validation_split, channels=channel_slice, shuffled_read=hdf5_shuffled_read)\n",
    "\n",
    "print('Train Data Shape =', train_data.shape)\n",
    "print('Val Data Shape =', val_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbc870d",
   "metadata": {
    "raw_mimetype": "text/html"
   },
   "source": [
    "# Configure and Train the Learning Model\n",
    "\n",
    "Here we configure the training model parameters. \n",
    "Training will be done for each color channel separately and saved with individual names based on:\n",
    "\n",
    "* `training_data_name`\n",
    "* `model_base_name`\n",
    "* `channel_name[i]`\n",
    "\n",
    "## Training debug tools\n",
    "\n",
    "You can monitor the progress during training with [TensorBoard](https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard) by starting it from the current working directory:\n",
    "\n",
    "    $ tensorboard --logdir=.\n",
    "\n",
    "Then connect to [http://localhost:6006/](http://localhost:6006/) with your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a2b0cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pydeep\\astro-csbdeep\\csbdeep\\models\\care_hdf5.py:46: UserWarning: small number of validation images (only 0.0% of all images)\n",
      "  warnings.warn(\"small number of validation images (only %.1f%% of all images)\" % (100*frac_val))\n",
      "d:\\pydeep\\astro-csbdeep\\.venv\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function _mean_or_not.<locals>.<lambda> at 0x000002040871E160> and will run it as-is.\n",
      "Cause: could not parse the source code of <function _mean_or_not.<locals>.<lambda> at 0x000002040871E160>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n",
      "Match 0:\n",
      "(lambda x: K.mean(x, axis=(- 1)))\n",
      "\n",
      "Match 1:\n",
      "(lambda x: x)\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function _mean_or_not.<locals>.<lambda> at 0x000002040871E160> and will run it as-is.\n",
      "Cause: could not parse the source code of <function _mean_or_not.<locals>.<lambda> at 0x000002040871E160>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n",
      "Match 0:\n",
      "(lambda x: K.mean(x, axis=(- 1)))\n",
      "\n",
      "Match 1:\n",
      "(lambda x: x)\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function _mean_or_not.<locals>.<lambda> at 0x000002040871E310> and will run it as-is.\n",
      "Cause: could not parse the source code of <function _mean_or_not.<locals>.<lambda> at 0x000002040871E310>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n",
      "Match 0:\n",
      "(lambda x: K.mean(x, axis=(- 1)))\n",
      "\n",
      "Match 1:\n",
      "(lambda x: x)\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function _mean_or_not.<locals>.<lambda> at 0x000002040871E310> and will run it as-is.\n",
      "Cause: could not parse the source code of <function _mean_or_not.<locals>.<lambda> at 0x000002040871E310>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n",
      "Match 0:\n",
      "(lambda x: K.mean(x, axis=(- 1)))\n",
      "\n",
      "Match 1:\n",
      "(lambda x: x)\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function _mean_or_not.<locals>.<lambda> at 0x000002040871E430> and will run it as-is.\n",
      "Cause: could not parse the source code of <function _mean_or_not.<locals>.<lambda> at 0x000002040871E430>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n",
      "Match 0:\n",
      "(lambda x: K.mean(x, axis=(- 1)))\n",
      "\n",
      "Match 1:\n",
      "(lambda x: x)\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function _mean_or_not.<locals>.<lambda> at 0x000002040871E430> and will run it as-is.\n",
      "Cause: could not parse the source code of <function _mean_or_not.<locals>.<lambda> at 0x000002040871E430>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n",
      "Match 0:\n",
      "(lambda x: K.mean(x, axis=(- 1)))\n",
      "\n",
      "Match 1:\n",
      "(lambda x: x)\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "200/200 [==============================] - 15s 52ms/step - loss: -0.2323 - mse: 0.0521 - mae: 0.0850 - val_loss: -0.9744 - val_mse: 0.0345 - val_mae: 0.0749\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 9s 43ms/step - loss: -1.0757 - mse: 0.0293 - mae: 0.0701 - val_loss: -1.1957 - val_mse: 0.0322 - val_mae: 0.0650\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 9s 43ms/step - loss: -1.2425 - mse: 0.0267 - mae: 0.0642 - val_loss: -1.2951 - val_mse: 0.0313 - val_mae: 0.0625\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 9s 45ms/step - loss: -1.2548 - mse: 0.0280 - mae: 0.0641 - val_loss: -1.2893 - val_mse: 0.0309 - val_mae: 0.0627\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.2846 - mse: 0.0264 - mae: 0.0630 - val_loss: -1.3238 - val_mse: 0.0306 - val_mae: 0.0614\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 9s 45ms/step - loss: -1.3011 - mse: 0.0300 - mae: 0.0626 - val_loss: -1.3433 - val_mse: 0.0305 - val_mae: 0.0609\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 9s 45ms/step - loss: -1.3057 - mse: 0.0236 - mae: 0.0621 - val_loss: -1.3492 - val_mse: 0.0305 - val_mae: 0.0606\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 9s 43ms/step - loss: -1.3019 - mse: 0.0313 - mae: 0.0622 - val_loss: -1.3552 - val_mse: 0.0303 - val_mae: 0.0604\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.3288 - mse: 0.0277 - mae: 0.0613 - val_loss: -1.3298 - val_mse: 0.0301 - val_mae: 0.0609\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.3052 - mse: 0.0347 - mae: 0.0623 - val_loss: -1.3478 - val_mse: 0.0294 - val_mae: 0.0602\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.3363 - mse: 0.0271 - mae: 0.0605 - val_loss: -1.3600 - val_mse: 0.0293 - val_mae: 0.0598\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.3164 - mse: 0.0309 - mae: 0.0621 - val_loss: -1.3691 - val_mse: 0.0285 - val_mae: 0.0595\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 9s 45ms/step - loss: -1.2991 - mse: 0.0339 - mae: 0.0626 - val_loss: -1.2829 - val_mse: 0.0284 - val_mae: 0.0621\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 9s 45ms/step - loss: -1.3187 - mse: 0.0337 - mae: 0.0620 - val_loss: -1.3685 - val_mse: 0.0283 - val_mae: 0.0595\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 9s 47ms/step - loss: -1.3440 - mse: 0.0270 - mae: 0.0606 - val_loss: -1.3677 - val_mse: 0.0276 - val_mae: 0.0594\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 10s 48ms/step - loss: -1.3596 - mse: 0.0280 - mae: 0.0594 - val_loss: -1.3715 - val_mse: 0.0276 - val_mae: 0.0593\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 9s 48ms/step - loss: -1.3286 - mse: 0.0389 - mae: 0.0612 - val_loss: -1.3575 - val_mse: 0.0276 - val_mae: 0.0596\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 9s 47ms/step - loss: -1.3488 - mse: 0.0274 - mae: 0.0602 - val_loss: -1.3758 - val_mse: 0.0273 - val_mae: 0.0591\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 9s 45ms/step - loss: -1.3681 - mse: 0.0283 - mae: 0.0594 - val_loss: -1.3750 - val_mse: 0.0271 - val_mae: 0.0591\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 9s 45ms/step - loss: -1.3578 - mse: 0.0281 - mae: 0.0600 - val_loss: -1.3550 - val_mse: 0.0271 - val_mae: 0.0596\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 9s 47ms/step - loss: -1.3277 - mse: 0.0292 - mae: 0.0613 - val_loss: -1.3739 - val_mse: 0.0271 - val_mae: 0.0590\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 9s 45ms/step - loss: -1.3468 - mse: 0.0276 - mae: 0.0605 - val_loss: -1.3788 - val_mse: 0.0269 - val_mae: 0.0589\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.3731 - mse: 0.0263 - mae: 0.0595 - val_loss: -1.3771 - val_mse: 0.0270 - val_mae: 0.0590\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.3503 - mse: 0.0270 - mae: 0.0599 - val_loss: -1.3767 - val_mse: 0.0266 - val_mae: 0.0590\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.3669 - mse: 0.0254 - mae: 0.0595 - val_loss: -1.3805 - val_mse: 0.0267 - val_mae: 0.0589\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.3632 - mse: 0.0285 - mae: 0.0597 - val_loss: -1.3767 - val_mse: 0.0265 - val_mae: 0.0590\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 9s 43ms/step - loss: -1.3618 - mse: 0.0376 - mae: 0.0598 - val_loss: -1.3701 - val_mse: 0.0267 - val_mae: 0.0591\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.3695 - mse: 0.0246 - mae: 0.0594 - val_loss: -1.3676 - val_mse: 0.0265 - val_mae: 0.0592\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.3530 - mse: 0.0306 - mae: 0.0600 - val_loss: -1.3760 - val_mse: 0.0265 - val_mae: 0.0589\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 9s 45ms/step - loss: -1.3364 - mse: 0.0270 - mae: 0.0611 - val_loss: -1.3803 - val_mse: 0.0263 - val_mae: 0.0589\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.3773 - mse: 0.0294 - mae: 0.0592 - val_loss: -1.3657 - val_mse: 0.0263 - val_mae: 0.0591\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.3756 - mse: 0.0334 - mae: 0.0593 - val_loss: -1.3810 - val_mse: 0.0265 - val_mae: 0.0588\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.3412 - mse: 0.0261 - mae: 0.0606 - val_loss: -1.3737 - val_mse: 0.0260 - val_mae: 0.0590\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.3688 - mse: 0.0270 - mae: 0.0594 - val_loss: -1.3800 - val_mse: 0.0261 - val_mae: 0.0588\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.3743 - mse: 0.0277 - mae: 0.0594 - val_loss: -1.3830 - val_mse: 0.0265 - val_mae: 0.0588\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.3670 - mse: 0.0257 - mae: 0.0594 - val_loss: -1.3846 - val_mse: 0.0266 - val_mae: 0.0587\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 9s 45ms/step - loss: -1.3487 - mse: 0.0254 - mae: 0.0603 - val_loss: -1.3687 - val_mse: 0.0259 - val_mae: 0.0592\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.3605 - mse: 0.0304 - mae: 0.0600 - val_loss: -1.3803 - val_mse: 0.0262 - val_mae: 0.0588\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.3452 - mse: 0.0294 - mae: 0.0604 - val_loss: -1.3740 - val_mse: 0.0261 - val_mae: 0.0589\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.3743 - mse: 0.0271 - mae: 0.0592 - val_loss: -1.3801 - val_mse: 0.0260 - val_mae: 0.0588\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.3518 - mse: 0.0234 - mae: 0.0601 - val_loss: -1.3853 - val_mse: 0.0257 - val_mae: 0.0587\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.3843 - mse: 0.0315 - mae: 0.0590 - val_loss: -1.3838 - val_mse: 0.0262 - val_mae: 0.0587\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.3773 - mse: 0.0230 - mae: 0.0586 - val_loss: -1.3800 - val_mse: 0.0259 - val_mae: 0.0589\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 9s 47ms/step - loss: -1.3735 - mse: 0.0227 - mae: 0.0592 - val_loss: -1.3850 - val_mse: 0.0258 - val_mae: 0.0586\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 9s 45ms/step - loss: -1.3561 - mse: 0.0304 - mae: 0.0604 - val_loss: -1.3795 - val_mse: 0.0258 - val_mae: 0.0588\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.3674 - mse: 0.0247 - mae: 0.0592 - val_loss: -1.3827 - val_mse: 0.0258 - val_mae: 0.0587\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.3721 - mse: 0.0313 - mae: 0.0598 - val_loss: -1.3867 - val_mse: 0.0258 - val_mae: 0.0586\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.3717 - mse: 0.0277 - mae: 0.0592 - val_loss: -1.3864 - val_mse: 0.0256 - val_mae: 0.0586\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.3969 - mse: 0.0229 - mae: 0.0583 - val_loss: -1.3853 - val_mse: 0.0258 - val_mae: 0.0586\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.3673 - mse: 0.0276 - mae: 0.0597 - val_loss: -1.3856 - val_mse: 0.0256 - val_mae: 0.0586\n",
      "\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "WARNING:tensorflow:From d:\\pydeep\\astro-csbdeep\\.venv\\lib\\site-packages\\tensorflow\\python\\saved_model\\signature_def_utils_impl.py:200: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: C:\\Users\\p7ayf\\AppData\\Local\\Temp\\tmpqohvnxj4\\model\\saved_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pydeep\\astro-csbdeep\\csbdeep\\utils\\tf.py:177: UserWarning: \n",
      "***IMPORTANT NOTE***\n",
      "\n",
      "You are using 'tensorflow' 2.x, hence it is likely that the exported model *will not work*\n",
      "in associated ImageJ/Fiji plugins (e.g. CSBDeep and StarDist).\n",
      "\n",
      "If you indeed have problems loading the exported model in Fiji, the current workaround is\n",
      "to load the trained model in a Python environment with installed 'tensorflow' 1.x and then\n",
      "export it again. If you need help with this, please read:\n",
      "\n",
      "https://gist.github.com/uschmidt83/4b747862fe307044c722d6d1009f6183\n",
      "\n",
      "  warnings.warn(\\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model exported in TensorFlow's SavedModel format:\n",
      "D:\\pydeep\\astro-csbdeep\\models\\NGC7000_NGC6888_p64_nPERC_PROB_spe400_e100_hdf5_main_R\\TF_SavedModel.zip\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function _mean_or_not.<locals>.<lambda> at 0x000002044BEB43A0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function _mean_or_not.<locals>.<lambda> at 0x000002044BEB43A0>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n",
      "Match 0:\n",
      "(lambda x: K.mean(x, axis=(- 1)))\n",
      "\n",
      "Match 1:\n",
      "(lambda x: x)\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function _mean_or_not.<locals>.<lambda> at 0x000002044BEB43A0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function _mean_or_not.<locals>.<lambda> at 0x000002044BEB43A0>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n",
      "Match 0:\n",
      "(lambda x: K.mean(x, axis=(- 1)))\n",
      "\n",
      "Match 1:\n",
      "(lambda x: x)\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function _mean_or_not.<locals>.<lambda> at 0x000002044BEB4550> and will run it as-is.\n",
      "Cause: could not parse the source code of <function _mean_or_not.<locals>.<lambda> at 0x000002044BEB4550>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n",
      "Match 0:\n",
      "(lambda x: K.mean(x, axis=(- 1)))\n",
      "\n",
      "Match 1:\n",
      "(lambda x: x)\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function _mean_or_not.<locals>.<lambda> at 0x000002044BEB4550> and will run it as-is.\n",
      "Cause: could not parse the source code of <function _mean_or_not.<locals>.<lambda> at 0x000002044BEB4550>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n",
      "Match 0:\n",
      "(lambda x: K.mean(x, axis=(- 1)))\n",
      "\n",
      "Match 1:\n",
      "(lambda x: x)\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function _mean_or_not.<locals>.<lambda> at 0x000002044BEB4670> and will run it as-is.\n",
      "Cause: could not parse the source code of <function _mean_or_not.<locals>.<lambda> at 0x000002044BEB4670>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n",
      "Match 0:\n",
      "(lambda x: K.mean(x, axis=(- 1)))\n",
      "\n",
      "Match 1:\n",
      "(lambda x: x)\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function _mean_or_not.<locals>.<lambda> at 0x000002044BEB4670> and will run it as-is.\n",
      "Cause: could not parse the source code of <function _mean_or_not.<locals>.<lambda> at 0x000002044BEB4670>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n",
      "Match 0:\n",
      "(lambda x: K.mean(x, axis=(- 1)))\n",
      "\n",
      "Match 1:\n",
      "(lambda x: x)\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "200/200 [==============================] - 10s 49ms/step - loss: -0.2510 - mse: 0.0881 - mae: 0.0809 - val_loss: -0.6822 - val_mse: 0.0785 - val_mae: 0.0866\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.1097 - mse: 0.0688 - mae: 0.0711 - val_loss: -1.2069 - val_mse: 0.0720 - val_mae: 0.0651\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.2947 - mse: 0.0768 - mae: 0.0629 - val_loss: -1.3028 - val_mse: 0.0741 - val_mae: 0.0624\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.3507 - mse: 0.0627 - mae: 0.0618 - val_loss: -1.4257 - val_mse: 0.0729 - val_mae: 0.0592\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.3797 - mse: 0.0542 - mae: 0.0603 - val_loss: -1.4093 - val_mse: 0.0710 - val_mae: 0.0586\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.4094 - mse: 0.0659 - mae: 0.0601 - val_loss: -1.4009 - val_mse: 0.0720 - val_mae: 0.0591\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.3967 - mse: 0.0493 - mae: 0.0603 - val_loss: -1.4796 - val_mse: 0.0707 - val_mae: 0.0580\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.4263 - mse: 0.0609 - mae: 0.0593 - val_loss: -1.4267 - val_mse: 0.0703 - val_mae: 0.0587\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.4538 - mse: 0.0609 - mae: 0.0587 - val_loss: -1.4831 - val_mse: 0.0695 - val_mae: 0.0578\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.4298 - mse: 0.0882 - mae: 0.0602 - val_loss: -1.4983 - val_mse: 0.0686 - val_mae: 0.0574\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 9s 45ms/step - loss: -1.4624 - mse: 0.0635 - mae: 0.0580 - val_loss: -1.4819 - val_mse: 0.0678 - val_mae: 0.0575\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.4290 - mse: 0.0494 - mae: 0.0596 - val_loss: -1.5000 - val_mse: 0.0662 - val_mae: 0.0571\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 9s 43ms/step - loss: -1.4380 - mse: 0.0848 - mae: 0.0598 - val_loss: -1.4738 - val_mse: 0.0652 - val_mae: 0.0575\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 9s 43ms/step - loss: -1.4520 - mse: 0.0924 - mae: 0.0596 - val_loss: -1.5097 - val_mse: 0.0655 - val_mae: 0.0568\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.4593 - mse: 0.0626 - mae: 0.0582 - val_loss: -1.4775 - val_mse: 0.0635 - val_mae: 0.0572\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.5009 - mse: 0.0836 - mae: 0.0565 - val_loss: -1.5116 - val_mse: 0.0634 - val_mae: 0.0566\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.4666 - mse: 0.0694 - mae: 0.0583 - val_loss: -1.4234 - val_mse: 0.0617 - val_mae: 0.0586\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.4754 - mse: 0.0683 - mae: 0.0576 - val_loss: -1.4620 - val_mse: 0.0610 - val_mae: 0.0573\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 9s 43ms/step - loss: -1.5011 - mse: 0.0705 - mae: 0.0567 - val_loss: -1.5053 - val_mse: 0.0599 - val_mae: 0.0567\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.4923 - mse: 0.0478 - mae: 0.0573 - val_loss: -1.4920 - val_mse: 0.0593 - val_mae: 0.0568\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.4532 - mse: 0.0551 - mae: 0.0586 - val_loss: -1.5025 - val_mse: 0.0580 - val_mae: 0.0565\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 9s 43ms/step - loss: -1.4698 - mse: 0.0760 - mae: 0.0584 - val_loss: -1.5146 - val_mse: 0.0570 - val_mae: 0.0563\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 9s 43ms/step - loss: -1.4994 - mse: 0.0835 - mae: 0.0578 - val_loss: -1.5185 - val_mse: 0.0567 - val_mae: 0.0562\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 9s 43ms/step - loss: -1.4937 - mse: 0.0515 - mae: 0.0568 - val_loss: -1.4898 - val_mse: 0.0567 - val_mae: 0.0569\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.5058 - mse: 0.0542 - mae: 0.0567 - val_loss: -1.5178 - val_mse: 0.0561 - val_mae: 0.0561\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 9s 43ms/step - loss: -1.4956 - mse: 0.0607 - mae: 0.0572 - val_loss: -1.5140 - val_mse: 0.0586 - val_mae: 0.0566\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.4756 - mse: 0.0807 - mae: 0.0578 - val_loss: -1.5043 - val_mse: 0.0560 - val_mae: 0.0563\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.4905 - mse: 0.0588 - mae: 0.0571 - val_loss: -1.4821 - val_mse: 0.0565 - val_mae: 0.0570\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.4861 - mse: 0.0612 - mae: 0.0570 - val_loss: -1.5227 - val_mse: 0.0559 - val_mae: 0.0561\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 9s 43ms/step - loss: -1.4644 - mse: 0.0603 - mae: 0.0585 - val_loss: -1.5172 - val_mse: 0.0560 - val_mae: 0.0561\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 9s 43ms/step - loss: -1.5126 - mse: 0.0659 - mae: 0.0567 - val_loss: -1.5096 - val_mse: 0.0561 - val_mae: 0.0563\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 9s 43ms/step - loss: -1.5094 - mse: 0.0731 - mae: 0.0566 - val_loss: -1.5211 - val_mse: 0.0555 - val_mae: 0.0560\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.4879 - mse: 0.0635 - mae: 0.0576 - val_loss: -1.5219 - val_mse: 0.0551 - val_mae: 0.0560\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 9s 45ms/step - loss: -1.5009 - mse: 0.0635 - mae: 0.0570 - val_loss: -1.5147 - val_mse: 0.0557 - val_mae: 0.0561\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.5076 - mse: 0.0667 - mae: 0.0570 - val_loss: -1.5211 - val_mse: 0.0547 - val_mae: 0.0560\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.4980 - mse: 0.0703 - mae: 0.0569 - val_loss: -1.5249 - val_mse: 0.0548 - val_mae: 0.0559\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.4774 - mse: 0.0488 - mae: 0.0576 - val_loss: -1.5237 - val_mse: 0.0549 - val_mae: 0.0559\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.4942 - mse: 0.0692 - mae: 0.0574 - val_loss: -1.5010 - val_mse: 0.0551 - val_mae: 0.0560\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 9s 43ms/step - loss: -1.4825 - mse: 0.0486 - mae: 0.0573 - val_loss: -1.5011 - val_mse: 0.0553 - val_mae: 0.0563\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.5022 - mse: 0.0658 - mae: 0.0567 - val_loss: -1.5048 - val_mse: 0.0546 - val_mae: 0.0563\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 9s 45ms/step - loss: -1.4829 - mse: 0.0624 - mae: 0.0575 - val_loss: -1.4862 - val_mse: 0.0550 - val_mae: 0.0566\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.5151 - mse: 0.0829 - mae: 0.0567 - val_loss: -1.5228 - val_mse: 0.0545 - val_mae: 0.0559\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.5264 - mse: 0.0431 - mae: 0.0555 - val_loss: -1.5270 - val_mse: 0.0543 - val_mae: 0.0559\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.5073 - mse: 0.0501 - mae: 0.0567 - val_loss: -1.5257 - val_mse: 0.0546 - val_mae: 0.0559\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.4881 - mse: 0.0785 - mae: 0.0581 - val_loss: -1.5235 - val_mse: 0.0549 - val_mae: 0.0559\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.5067 - mse: 0.0525 - mae: 0.0565 - val_loss: -1.5261 - val_mse: 0.0547 - val_mae: 0.0558\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.5037 - mse: 0.0813 - mae: 0.0576 - val_loss: -1.5283 - val_mse: 0.0539 - val_mae: 0.0558\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 9s 45ms/step - loss: -1.5007 - mse: 0.0576 - mae: 0.0565 - val_loss: -1.5256 - val_mse: 0.0536 - val_mae: 0.0558\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.5334 - mse: 0.0487 - mae: 0.0556 - val_loss: -1.5275 - val_mse: 0.0540 - val_mae: 0.0557\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.4979 - mse: 0.0649 - mae: 0.0572 - val_loss: -1.5250 - val_mse: 0.0539 - val_mae: 0.0558\n",
      "\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: C:\\Users\\p7ayf\\AppData\\Local\\Temp\\tmpc6g_et2n\\model\\saved_model.pb\n",
      "\n",
      "Model exported in TensorFlow's SavedModel format:\n",
      "D:\\pydeep\\astro-csbdeep\\models\\NGC7000_NGC6888_p64_nPERC_PROB_spe400_e100_hdf5_main_G\\TF_SavedModel.zip\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function _mean_or_not.<locals>.<lambda> at 0x000002045E5569D0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function _mean_or_not.<locals>.<lambda> at 0x000002045E5569D0>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n",
      "Match 0:\n",
      "(lambda x: K.mean(x, axis=(- 1)))\n",
      "\n",
      "Match 1:\n",
      "(lambda x: x)\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function _mean_or_not.<locals>.<lambda> at 0x000002045E5569D0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function _mean_or_not.<locals>.<lambda> at 0x000002045E5569D0>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n",
      "Match 0:\n",
      "(lambda x: K.mean(x, axis=(- 1)))\n",
      "\n",
      "Match 1:\n",
      "(lambda x: x)\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function _mean_or_not.<locals>.<lambda> at 0x000002045E556820> and will run it as-is.\n",
      "Cause: could not parse the source code of <function _mean_or_not.<locals>.<lambda> at 0x000002045E556820>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n",
      "Match 0:\n",
      "(lambda x: K.mean(x, axis=(- 1)))\n",
      "\n",
      "Match 1:\n",
      "(lambda x: x)\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function _mean_or_not.<locals>.<lambda> at 0x000002045E556820> and will run it as-is.\n",
      "Cause: could not parse the source code of <function _mean_or_not.<locals>.<lambda> at 0x000002045E556820>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n",
      "Match 0:\n",
      "(lambda x: K.mean(x, axis=(- 1)))\n",
      "\n",
      "Match 1:\n",
      "(lambda x: x)\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function _mean_or_not.<locals>.<lambda> at 0x000002045E5563A0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function _mean_or_not.<locals>.<lambda> at 0x000002045E5563A0>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n",
      "Match 0:\n",
      "(lambda x: K.mean(x, axis=(- 1)))\n",
      "\n",
      "Match 1:\n",
      "(lambda x: x)\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function _mean_or_not.<locals>.<lambda> at 0x000002045E5563A0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function _mean_or_not.<locals>.<lambda> at 0x000002045E5563A0>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.\n",
      "Match 0:\n",
      "(lambda x: K.mean(x, axis=(- 1)))\n",
      "\n",
      "Match 1:\n",
      "(lambda x: x)\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "200/200 [==============================] - 10s 49ms/step - loss: -0.4310 - mse: 0.1209 - mae: 0.0948 - val_loss: -0.8755 - val_mse: 0.1127 - val_mae: 0.0868\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.0479 - mse: 0.0848 - mae: 0.0797 - val_loss: -1.1610 - val_mse: 0.1053 - val_mae: 0.0751\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.1444 - mse: 0.1033 - mae: 0.0759 - val_loss: -1.1179 - val_mse: 0.1020 - val_mae: 0.0766\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.1733 - mse: 0.0994 - mae: 0.0752 - val_loss: -1.2187 - val_mse: 0.1014 - val_mae: 0.0731\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.1862 - mse: 0.0813 - mae: 0.0740 - val_loss: -1.1599 - val_mse: 0.1014 - val_mae: 0.0740\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.1949 - mse: 0.1106 - mae: 0.0741 - val_loss: -1.2445 - val_mse: 0.1007 - val_mae: 0.0717\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.2117 - mse: 0.0902 - mae: 0.0732 - val_loss: -1.2446 - val_mse: 0.1026 - val_mae: 0.0716\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.2227 - mse: 0.0979 - mae: 0.0726 - val_loss: -1.2521 - val_mse: 0.1029 - val_mae: 0.0716\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.2434 - mse: 0.0915 - mae: 0.0721 - val_loss: -1.2589 - val_mse: 0.1005 - val_mae: 0.0713\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.2078 - mse: 0.1292 - mae: 0.0741 - val_loss: -1.2527 - val_mse: 0.0993 - val_mae: 0.0711\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.2392 - mse: 0.1043 - mae: 0.0718 - val_loss: -1.2678 - val_mse: 0.0979 - val_mae: 0.0708\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.2110 - mse: 0.0753 - mae: 0.0734 - val_loss: -1.2669 - val_mse: 0.0973 - val_mae: 0.0707\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 9s 43ms/step - loss: -1.2104 - mse: 0.1066 - mae: 0.0738 - val_loss: -1.1356 - val_mse: 0.0966 - val_mae: 0.0741\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.2122 - mse: 0.1076 - mae: 0.0738 - val_loss: -1.1944 - val_mse: 0.0974 - val_mae: 0.0727\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.2273 - mse: 0.0877 - mae: 0.0722 - val_loss: -1.2708 - val_mse: 0.0966 - val_mae: 0.0705\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.2695 - mse: 0.0967 - mae: 0.0701 - val_loss: -1.2770 - val_mse: 0.1028 - val_mae: 0.0706\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.2432 - mse: 0.1152 - mae: 0.0725 - val_loss: -1.2314 - val_mse: 0.0949 - val_mae: 0.0714\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.2514 - mse: 0.1011 - mae: 0.0714 - val_loss: -1.2426 - val_mse: 0.0957 - val_mae: 0.0710\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.2651 - mse: 0.1106 - mae: 0.0708 - val_loss: -1.2791 - val_mse: 0.0946 - val_mae: 0.0702\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 9s 45ms/step - loss: -1.2596 - mse: 0.0845 - mae: 0.0712 - val_loss: -1.2784 - val_mse: 0.0949 - val_mae: 0.0704\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.2330 - mse: 0.0963 - mae: 0.0726 - val_loss: -1.2793 - val_mse: 0.0955 - val_mae: 0.0702\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.2335 - mse: 0.1038 - mae: 0.0727 - val_loss: -1.2676 - val_mse: 0.0950 - val_mae: 0.0704\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 9s 45ms/step - loss: -1.2708 - mse: 0.1166 - mae: 0.0716 - val_loss: -1.2807 - val_mse: 0.0941 - val_mae: 0.0700\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.2636 - mse: 0.1051 - mae: 0.0707 - val_loss: -1.2465 - val_mse: 0.0960 - val_mae: 0.0716\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.2658 - mse: 0.0923 - mae: 0.0707 - val_loss: -1.2810 - val_mse: 0.0942 - val_mae: 0.0701\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.2616 - mse: 0.0958 - mae: 0.0711 - val_loss: -1.2831 - val_mse: 0.0925 - val_mae: 0.0700\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.2636 - mse: 0.1212 - mae: 0.0714 - val_loss: -1.2814 - val_mse: 0.0925 - val_mae: 0.0700\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 9s 43ms/step - loss: -1.2682 - mse: 0.0944 - mae: 0.0707 - val_loss: -1.2399 - val_mse: 0.0933 - val_mae: 0.0712\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.2599 - mse: 0.1024 - mae: 0.0709 - val_loss: -1.2847 - val_mse: 0.0934 - val_mae: 0.0700\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.2347 - mse: 0.1043 - mae: 0.0727 - val_loss: -1.2805 - val_mse: 0.0918 - val_mae: 0.0701\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 9s 45ms/step - loss: -1.2795 - mse: 0.1096 - mae: 0.0705 - val_loss: -1.2803 - val_mse: 0.0949 - val_mae: 0.0700\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.2742 - mse: 0.1105 - mae: 0.0705 - val_loss: -1.2653 - val_mse: 0.0950 - val_mae: 0.0705\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.2436 - mse: 0.0962 - mae: 0.0720 - val_loss: -1.2733 - val_mse: 0.0948 - val_mae: 0.0703\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 9s 43ms/step - loss: -1.2672 - mse: 0.1010 - mae: 0.0711 - val_loss: -1.2766 - val_mse: 0.0943 - val_mae: 0.0701\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.2785 - mse: 0.1107 - mae: 0.0710 - val_loss: -1.2868 - val_mse: 0.0937 - val_mae: 0.0698\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.2580 - mse: 0.0989 - mae: 0.0710 - val_loss: -1.2830 - val_mse: 0.0937 - val_mae: 0.0700\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.2460 - mse: 0.0873 - mae: 0.0717 - val_loss: -1.2799 - val_mse: 0.0942 - val_mae: 0.0700\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.2547 - mse: 0.1198 - mae: 0.0718 - val_loss: -1.2810 - val_mse: 0.0952 - val_mae: 0.0699\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.2446 - mse: 0.0858 - mae: 0.0717 - val_loss: -1.2692 - val_mse: 0.0912 - val_mae: 0.0704\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.2659 - mse: 0.1066 - mae: 0.0708 - val_loss: -1.2790 - val_mse: 0.0927 - val_mae: 0.0699\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.2493 - mse: 0.0869 - mae: 0.0714 - val_loss: -1.2272 - val_mse: 0.0935 - val_mae: 0.0712\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 9s 45ms/step - loss: -1.2838 - mse: 0.1262 - mae: 0.0707 - val_loss: -1.2874 - val_mse: 0.0901 - val_mae: 0.0697\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.2851 - mse: 0.0700 - mae: 0.0692 - val_loss: -1.2851 - val_mse: 0.0933 - val_mae: 0.0699\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 9s 43ms/step - loss: -1.2729 - mse: 0.0862 - mae: 0.0706 - val_loss: -1.2853 - val_mse: 0.0911 - val_mae: 0.0697\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.2528 - mse: 0.1103 - mae: 0.0721 - val_loss: -1.2789 - val_mse: 0.0914 - val_mae: 0.0699\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 9s 44ms/step - loss: -1.2787 - mse: 0.0832 - mae: 0.0702 - val_loss: -1.2862 - val_mse: 0.0912 - val_mae: 0.0698\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 9s 46ms/step - loss: -1.2674 - mse: 0.1302 - mae: 0.0715 - val_loss: -1.2786 - val_mse: 0.0894 - val_mae: 0.0697\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 9s 46ms/step - loss: -1.2687 - mse: 0.0897 - mae: 0.0705 - val_loss: -1.2872 - val_mse: 0.0889 - val_mae: 0.0696\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 9s 45ms/step - loss: -1.2982 - mse: 0.0852 - mae: 0.0693 - val_loss: -1.2892 - val_mse: 0.0902 - val_mae: 0.0696\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 9s 46ms/step - loss: -1.2647 - mse: 0.1013 - mae: 0.0711 - val_loss: -1.2786 - val_mse: 0.0891 - val_mae: 0.0698\n",
      "\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: C:\\Users\\p7ayf\\AppData\\Local\\Temp\\tmp_4nsr71s\\model\\saved_model.pb\n",
      "\n",
      "Model exported in TensorFlow's SavedModel format:\n",
      "D:\\pydeep\\astro-csbdeep\\models\\NGC7000_NGC6888_p64_nPERC_PROB_spe400_e100_hdf5_main_B\\TF_SavedModel.zip\n"
     ]
    }
   ],
   "source": [
    "# Importing the deep learning framework\n",
    "from csbdeep.models import Config, CARE, HDF5CARE\n",
    "\n",
    "# Since we are training each channel separately: n_channel_in, n_channel_out = 1, 1\n",
    "# Probabilistic training will be used as this yields better results\n",
    "# Reccomended that train_steps_per_epoch set at 200-400, and train_epochs at 100-200 for good results.\n",
    "config = Config('SYXC', n_channel_in=1, n_channel_out=1, unet_kern_size=3, probabilistic=True, train_steps_per_epoch=200, train_epochs=50)\n",
    "\n",
    "# Give a name for the model\n",
    "model_base_name = '_PROB_spe400_e100_hdf5_main'\n",
    "\n",
    "model_name = training_data_name + model_base_name\n",
    "skipindex = [ ]\n",
    "channel_names=['R', 'G', 'B']\n",
    "for i, channel in enumerate(channel_names):\n",
    "    if i in skipindex:\n",
    "        continue\n",
    "    \n",
    "    # update the HDF5 iterable channel slice selection\n",
    "    train_data.set_channel(slice(i,i+1))\n",
    "    val_data.set_channel(slice(i,i+1))\n",
    "\n",
    "    full_model_name = model_name + '_' + channel\n",
    "    \n",
    "    # Create the Learning Model from the CARE framework with configuration\n",
    "    model = HDF5CARE(config, name=full_model_name, basedir='models')\n",
    "        \n",
    "    # Train the model and capture history\n",
    "    history = model.train(\n",
    "        XY_data=train_data, validation_data=val_data[:])\n",
    "    \n",
    "    # Save the model\n",
    "    model.export_TF()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc2eadc",
   "metadata": {},
   "source": [
    "# Load and De-noise an Image \n",
    "\n",
    "Here we load an example image to de-noise using the trained set of RGB models.\n",
    "\n",
    "The image to be de-noised must be normalized in the same way as the training data.\n",
    "Then for each channel the model is used to predict the de-noised output and these are then saved as a single RGB image.\n",
    "\n",
    "The example test image used can be downloaded [here](https://1drv.ms/u/s!AvWEkn9Anb_Nq9Aw52Xs3LuYEcq_rg?e=EexXxL).\n",
    "\n",
    "Place the test image in the `data/astro/test` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a086c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Image size = (2771, 4048, 3)\n",
      "Test Image axes = YX\n"
     ]
    }
   ],
   "source": [
    "# Specify the test file\n",
    "test_file_name='CrescentNebula-NoSt-Deep.tiff'\n",
    "#test_file_name='FireDog-Comb33-NoSt.tiff'\n",
    "\n",
    "testfilepath=basepath/'test'/test_file_name\n",
    "x = imread(testfilepath)\n",
    "testaxes = 'YX'\n",
    "\n",
    "print('Test Image size =', x.shape)\n",
    "print('Test Image axes =', testaxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f547edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: NGC7000_NGC6888_p64_nPERC_PROB_spe400_e100_hdf5_main_R\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Out of memory, retrying with n_tiles = (1, 2)\n",
      "Out of memory, retrying with n_tiles = (2, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  9.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: NGC7000_NGC6888_p64_nPERC_PROB_spe400_e100_hdf5_main_G\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Out of memory, retrying with n_tiles = (1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: NGC7000_NGC6888_p64_nPERC_PROB_spe400_e100_hdf5_main_B\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Out of memory, retrying with n_tiles = (1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  8.13it/s]\n"
     ]
    }
   ],
   "source": [
    "from csbdeep.data import PercentileNormalizer, PadAndCropResizer, ReinhardNormalizer, NoNormalizer\n",
    "\n",
    "channel_names=['R', 'G', 'B']\n",
    "output_denoised = []\n",
    "for i, channel in enumerate(channel_names):\n",
    "    full_model_name = model_name + '_' + channel\n",
    "    \n",
    "    # Load the model for the specific channel\n",
    "    print(\"Loading model:\", full_model_name)\n",
    "    model = HDF5CARE(config=None, name=full_model_name, basedir='models')\n",
    "\n",
    "    # Predict/de-noise the image channel with the corresponding trained model\n",
    "    # Default PercentileNormalizer is used to match the normalization used to train the model\n",
    "    output_denoised.append(\n",
    "        model.predict(x[:,:,i],testaxes, normalizer=PercentileNormalizer(), resizer=PadAndCropResizer())\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b105b015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: (No file associated with this HDUList)\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU       7   (4048, 2771, 3)   float32   \n",
      "Output file saved: data\\astro\\test\\NGC7000_NGC6888_p64_nPERC_PROB_spe400_e100_hdf5_main_RGB_CrescentNebula-NoSt-Deep.fits\n"
     ]
    }
   ],
   "source": [
    "# Load astropy library for saving the de-noised image in fits format\n",
    "from astropy.io import fits\n",
    "\n",
    "output_file_name = model_name + '_RGB_' + Path(test_file_name).stem + '.fits'\n",
    "output_file_path = basepath/'test'/output_file_name\n",
    "hdu = fits.PrimaryHDU(output_denoised)\n",
    "hdul = fits.HDUList([hdu])\n",
    "hdul.info()\n",
    "hdul.writeto(output_file_path)\n",
    "print(\"Output file saved:\", output_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
