{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f264797d",
   "metadata": {},
   "source": [
    "# Training with large datasets\n",
    "\n",
    "In order to allow larger sets of data to be processed with limited system memory we take advantage of HDF5 and the [h5py package](https://www.h5py.org/).\n",
    "\n",
    "This allows us to incrementally save our pre-processed and randomised data to disk, and then incrementally load the data using iterable tensors for training.\n",
    "\n",
    "In contrast to the main example notebook `AstroNoise2Noise.ipynb`, in this example we train with two sets of subs from different targets resulting in substantially more data.\n",
    "\n",
    "*Enhancements have been provided by Maria Pavlou as code changes to the base CDBDeep repo.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "509cfb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow reloading of CSBDeep modules following any code changes\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# A couple required imports\n",
    "import numpy as np\n",
    "from tifffile import imread\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7361afc9",
   "metadata": {},
   "source": [
    "# Pre-processing Training Data and Save\n",
    "\n",
    "We have two sets of sub frames in the `data/astro` sub-folders `NGC6888` and `NGC7000`, acquired with the same optical train and equipment.\n",
    "\n",
    "All images have been aligned and calibrated and saved in the tiff format.\n",
    "\n",
    "The example data can be downloaded [here](https://1drv.ms/u/s!AvWEkn9Anb_Nq9Aw52Xs3LuYEcq_rg?e=EexXxL)\n",
    "\n",
    "Place the train images in sub-folders under the `data/astro` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a5bcc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Data Parameters:\n",
    "# Root Data path\n",
    "basepath=Path('data/astro')\n",
    "# Train Data path/s\n",
    "source_dirs=['NGC6888','NGC7000']\n",
    "# Image file pattern. Note: only formats supported by imread currently\n",
    "pattern='*.tiff'\n",
    "# Image patch size\n",
    "patchsize=64\n",
    "# Training data output savefile path & name\n",
    "training_data_name=\"_\".join(str(s) for s in source_dirs) + \"_p{0}\".format(patchsize) + '_NoPreProcessor' + '_NormPerc'\n",
    "training_data_filename=training_data_name + '.hdf5'\n",
    "save_file=basepath/training_data_filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f30eeadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an estimate of the number of non-overlapping patches for the images we have, sampling from the first we find.\n",
    "first_image_file = list((basepath/source_dirs[0]).glob(pattern))[0]\n",
    "sampleimage = imread(first_image_file)\n",
    "n_patches_per_image=np.int(sampleimage.shape[0]/patchsize)*np.int(sampleimage.shape[1]/patchsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8485ba39",
   "metadata": {},
   "source": [
    "# Save pre-processed data to HDF5\n",
    "\n",
    "No we use the `create_patches_hdf5` helper to create the sampled patches from the sub frame images, and store these directly to disk as an HDF5 file.\n",
    "\n",
    "**Note:**\n",
    "\n",
    "* Saving to disk will take longer, and significantly longer depending on your system configuration\n",
    "* Randomised indexing cannot be used when writing to HDF5 Datasets. A secondary read/write process is used to achieve a compromised shuffle on the raw data. This can take some time, but leads to improved performance during training. A good tradeoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268658ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from csbdeep.data import RawData, create_patches, create_patches_hdf5, norm_percentiles, norm_reinhard\n",
    "from csbdeep.data import NoPreProcessor, ReinhardPreProcessor\n",
    "\n",
    "# Load image pairs for Noise2Noise processing, each image paired against every other at most once.\n",
    "raw_data = RawData.from_folder_n2n(basepath, source_dirs=source_dirs, axes='YXC', pattern=pattern, preprocessor=NoPreProcessor(), imageloader=None)\n",
    "\n",
    "# Create patch data from image pairs with parameters,\n",
    "# normalization set as norm_percentiles() by default, optionally set to None, norm_reinhard() or other custom\n",
    "create_patches_hdf5(\n",
    "    raw_data, \n",
    "    patch_size=(patchsize,patchsize,3),\n",
    "    normalization=norm_percentiles(),\n",
    "    n_patches_per_image=n_patches_per_image,\n",
    "    save_file=save_file,\n",
    "    patch_filter=None,\n",
    "    overlap=False,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47711ff",
   "metadata": {},
   "source": [
    "# Load Training Data\n",
    "Here we load the training data from a save file created in earlier steps.\n",
    "As data is loaded we can also split the data into training `X,Y` and validation `X_val,Y_val` sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc39ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from csbdeep.data.generate_hdf5 import HDF5Data\n",
    "\n",
    "# Train/Validation split %\n",
    "validation_split=0.1\n",
    "# Select 1st channel initially\n",
    "channel_slice = slice(0,1)\n",
    "# Since we have shuffles the raw data we disable this for performance\n",
    "hdf5_shuffled_read = False\n",
    "\n",
    "# Load saved training and validation from HDF5 data with iterable wrapper object and channel selection\n",
    "train_data, val_data = HDF5Data.from_hdf5(save_file, validation_split=validation_split, channels=channel_slice, shuffled_read=hdf5_shuffled_read)\n",
    "\n",
    "print('Train Data Shape =', train_data.shape)\n",
    "print('Val Data Shape =', val_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbc870d",
   "metadata": {
    "raw_mimetype": "text/html"
   },
   "source": [
    "# Configure and Train the Learning Model\n",
    "\n",
    "Here we configure the training model parameters. \n",
    "Training will be done for each color channel separately and saved with individual names based on:\n",
    "\n",
    "* `training_data_name`\n",
    "* `model_base_name`\n",
    "* `channel_name[i]`\n",
    "\n",
    "## Training debug tools\n",
    "\n",
    "You can monitor the progress during training with [TensorBoard](https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard) by starting it from the current working directory:\n",
    "\n",
    "    $ tensorboard --logdir=.\n",
    "\n",
    "Then connect to [http://localhost:6006/](http://localhost:6006/) with your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2b0cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the deep learning framework\n",
    "from csbdeep.models import Config, HDF5CARE\n",
    "\n",
    "# Probabilistic training will be used as this yields better results\n",
    "probabilistic=True\n",
    "# Reccomended as large a batch size as can fit into GPU memory for your patch size.\n",
    "train_batch_size = 128\n",
    "# The number of training epochs to execute over all\n",
    "train_epochs=50\n",
    "# The number of passes over the training data that should be completed over the number of epochs\n",
    "train_passes=4\n",
    "train_steps_per_epoch = int(np.ceil(((len(train_data)*train_passes)/train_epochs)/train_batch_size))\n",
    "\n",
    "# Since we are training each channel separately: n_channel_in, n_channel_out = 1, 1\n",
    "config = Config('SYXC', n_channel_in=1, n_channel_out=1, unet_kern_size=3, probabilistic=probabilistic, train_steps_per_epoch=train_steps_per_epoch, train_epochs=train_epochs, train_batch_size=train_batch_size)\n",
    "\n",
    "# Give a name for the model\n",
    "version=1\n",
    "model_base_name = \"_PRB-{0}_B{1}_SPE{2}_E{3}_V{4}\".format(probabilistic,train_batch_size,train_steps_per_epoch,train_epochs,version)\n",
    "model_name = training_data_name + model_base_name\n",
    "\n",
    "skipindex = [ ]\n",
    "channel_names=['R', 'G', 'B']\n",
    "for i, channel in enumerate(channel_names):\n",
    "    if i in skipindex:\n",
    "        continue\n",
    "    \n",
    "    # update the HDF5 iterable channel slice selection\n",
    "    train_data.set_channel(slice(i,i+1))\n",
    "    val_data.set_channel(slice(i,i+1))\n",
    "\n",
    "    # Generate a model name for each channel\n",
    "    full_model_name = model_name + '_' + channel\n",
    "    print(\"Train model name: \",model_name)\n",
    "    \n",
    "    # Create the Learning Model from the CARE framework with configuration\n",
    "    model = HDF5CARE(config, name=full_model_name, basedir='models')\n",
    "        \n",
    "    # Train the model and capture history\n",
    "    history = model.train(\n",
    "        XY_data=train_data, validation_data=val_data)\n",
    "    \n",
    "    # Save the model\n",
    "    model.export_TF()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc2eadc",
   "metadata": {},
   "source": [
    "# Load and De-noise an Image \n",
    "\n",
    "Here we load an example image to de-noise using the trained set of RGB models.\n",
    "\n",
    "The image to be de-noised must be normalized in the same way as the training data.\n",
    "Then for each channel the model is used to predict the de-noised output and these are then saved as a single RGB image.\n",
    "\n",
    "The example test image used can be downloaded [here](https://1drv.ms/u/s!AvWEkn9Anb_Nq9Aw52Xs3LuYEcq_rg?e=EexXxL).\n",
    "\n",
    "Place the test image in the `data/astro/test` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a086c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the test file\n",
    "test_file_name='CrescentNebula-NoSt-Deep.tiff'\n",
    "\n",
    "testfilepath=basepath/'test'/test_file_name\n",
    "x = imread(testfilepath)\n",
    "testaxes = 'YX'\n",
    "\n",
    "print('Test Image size =', x.shape)\n",
    "print('Test Image axes =', testaxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f547edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from csbdeep.data import PercentileNormalizer, PadAndCropResizer, ReinhardNormalizer, NoNormalizer\n",
    "\n",
    "channel_names=['R', 'G', 'B']\n",
    "output_denoised = []\n",
    "for i, channel in enumerate(channel_names):\n",
    "    full_model_name = model_name + '_' + channel\n",
    "    \n",
    "    # Load the model for the specific channel\n",
    "    print(\"Loading model:\", full_model_name)\n",
    "    model = HDF5CARE(config=None, name=full_model_name, basedir='models')\n",
    "\n",
    "    # Predict/de-noise the image channel with the corresponding trained model\n",
    "    # Default PercentileNormalizer is used to match the normalization used to train the model\n",
    "    output_denoised.append(\n",
    "        model.predict(x[:,:,i],testaxes, normalizer=PercentileNormalizer(), resizer=PadAndCropResizer(), n_tiles = (2, 4))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b105b015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load astropy library for saving the de-noised image in fits format\n",
    "from astropy.io import fits\n",
    "\n",
    "output_file_name = model_name + '_RGB_' + Path(test_file_name).stem + '.fits'\n",
    "output_file_path = basepath/'test'/output_file_name\n",
    "hdu = fits.PrimaryHDU(output_denoised)\n",
    "hdul = fits.HDUList([hdu])\n",
    "hdul.info()\n",
    "hdul.writeto(output_file_path)\n",
    "print(\"Output file saved:\", output_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
